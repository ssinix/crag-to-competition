{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "This Python script merges climbing data from two distinct sources: the 8anu climbing dataset and the IFSC climbers dataset. The purpose of this script is to combine relevant climber information, including performance metrics from both datasets, into a unified CSV file for further analysis.\n",
    "\n",
    "### Datasets\n",
    "1. **8anu Climbing Data** (`8anu_climbing_data.csv`): Contains climber names along with their highest recorded grade, count of 8c+ routes climbed, and average grade of their first five ascents.\n",
    "2. **IFSC Climbers Data** (`ifsc_climbers.csv`): Provides climber details such as country, gender, and competition points across boulder, lead, and combined disciplines.\n",
    "\n",
    "For more information on how these data were scraped, you can check out the previous notebooks.\n",
    "\n",
    "### Output\n",
    "The resulting dataset includes the following columns:\n",
    "- `name`: Climber's name (as appears in 8anu data)\n",
    "- `country`: Climber's country (from IFSC data)\n",
    "- `gender`: Climber's gender (from IFSC data)\n",
    "- `boulder_points`: Points in boulder discipline (from IFSC data)\n",
    "- `lead_points`: Points in lead discipline (from IFSC data)\n",
    "- `combined_points`: Points in combined discipline (from IFSC data)\n",
    "- `highest_grade`: Highest grade achieved (from 8anu data)\n",
    "- `count_8c_plus`: Number of 8c+ routes climbed (from 8anu data)\n",
    "- `avg_grade_first5`: Average grade of first five ascents (from 8anu data)\n",
    "\n",
    "This merged dataset provides a comprehensive view of climbers' performance across both competitive and outdoor climbing metrics."
   ],
   "id": "d8338a125a9dd5d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start with the imports",
   "id": "dfd128d3fd3f78ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:58:42.698958Z",
     "start_time": "2025-04-01T14:58:42.337253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "id": "19a56e9a90c72fa9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, let's read the datasets `8anu_climbing_data.csv` and `ifsc_climbers.csv`",
   "id": "f0ac35bef0bac99d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:58:43.719955Z",
     "start_time": "2025-04-01T14:58:43.694802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the datasets\n",
    "anu_data = pd.read_csv(\"../data/8anu_data/8anu_climbing_data.csv\")\n",
    "ifsc_data = pd.read_csv(\"../data/ifsc_data/ifsc_climbers.csv\")\n",
    "\n",
    "# Create a dictionary from IFSC data for faster lookup (case-insensitive)\n",
    "ifsc_dict = {row['name'].lower(): row for _, row in ifsc_data.iterrows()}\n",
    "\n",
    "# Prepare the output data\n",
    "merged_data = []"
   ],
   "id": "950b62d5391ce912",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's loop through the 8anu dataset, pulling each climberâ€™s name and matching it (case-insensitive) with IFSC data and add it to the merged data.",
   "id": "a2ef368b2e553028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:58:44.815568Z",
     "start_time": "2025-04-01T14:58:44.806488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loop through 8anu dataset\n",
    "for _, anu_row in anu_data.iterrows():\n",
    "    # Get the name (keep it capitalized as in original)\n",
    "    name = anu_row['name']\n",
    "\n",
    "    # Try to find matching IFSC data (case-insensitive)\n",
    "    ifsc_row = ifsc_dict.get(name.lower())\n",
    "\n",
    "    # Create new row with all required fields\n",
    "    new_row = {\n",
    "        'name': name,\n",
    "        'country': ifsc_row['country'] if ifsc_row is not None else '',\n",
    "        'gender': ifsc_row['gender'] if ifsc_row is not None else '',\n",
    "        'boulder_points': ifsc_row['boulder_points'] if ifsc_row is not None else '',\n",
    "        'lead_points': ifsc_row['lead_points'] if ifsc_row is not None else '',\n",
    "        'combined_points': ifsc_row['combined_points'] if ifsc_row is not None else '',\n",
    "        'highest_grade': anu_row['highest_grade'],\n",
    "        'count_8c_plus': anu_row['count_8c_plus'],\n",
    "        'avg_grade_first5': anu_row['avg_grade_first5']\n",
    "    }\n",
    "\n",
    "    merged_data.append(new_row)"
   ],
   "id": "14590a800d1d132b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Finally, let's convert the merged data into a DataFrame, reorder the columns and save it to a csv.",
   "id": "ff0f65c44fe0a46a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T14:58:46.386172Z",
     "start_time": "2025-04-01T14:58:46.377523Z"
    }
   },
   "source": [
    "# Create final DataFrame\n",
    "result_df = pd.DataFrame(merged_data)\n",
    "\n",
    "# Define the column order\n",
    "column_order = ['name', 'country', 'gender', 'boulder_points', 'lead_points',\n",
    "                'combined_points', 'highest_grade', 'count_8c_plus', 'avg_grade_first5']\n",
    "\n",
    "\n",
    "output_dir = \"../data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "temp_output_path = os.path.join(output_dir, \"merged_climbing_data.csv\")\n",
    "result_df.to_csv(temp_output_path, index=False)\n",
    "\n",
    "print(\"Merged dataset saved to 'merged_climbing_data.csv'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to 'merged_climbing_data.csv'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's preview the final dataset",
   "id": "f2594d1185f1be0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nFirst few rows of the result:\")\n",
    "result_df.head()"
   ],
   "id": "1f2f978b9ec37bd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
