{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This notebook scrapes climber names, country of the climber and total points by category from the International Federation of Sport Climbing (IFSC) rankings website. It extracts data for both boulder and lead categories, for men and women.\n"
   ],
   "id": "f021dd3090ba837d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T11:58:07.753092Z",
     "start_time": "2025-03-24T11:57:47.079714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "### Scraping IFSC with Robust Points Extraction (unchanged)\n",
    "def scrape_ifsc_data(url, category_name):\n",
    "    \"\"\"Scrape climber names, countries, and points using Selenium with debugging.\"\"\"\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    print(f\"Scraping {category_name} from {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle cookie popup with a slight delay\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", accept_button)\n",
    "        print(f\"Accepted cookie popup for {category_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No cookie popup found or error accepting it for {category_name}: {e}\")\n",
    "\n",
    "    # Determine discipline from category_name\n",
    "    if \"combined\" in category_name:\n",
    "        discipline = \"combined\"\n",
    "        tab_name = \"Boulder & Lead\"\n",
    "    elif \"lead\" in category_name:\n",
    "        discipline = \"lead\"\n",
    "        tab_name = \"Lead\"\n",
    "    else:\n",
    "        discipline = \"boulder\"\n",
    "        tab_name = \"Boulder\"\n",
    "\n",
    "    # Click the appropriate tab\n",
    "    try:\n",
    "        tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//a[contains(@class, 'd3-ty-navigation-large') and contains(text(), '{tab_name}')]\"))\n",
    "        )\n",
    "        tab.click()\n",
    "        print(f\"Clicked '{tab_name}' tab for {category_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"font-normal\"))\n",
    "        )\n",
    "        print(f\"{tab_name} rankings data loaded for {category_name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not click '{tab_name}' tab or load data for {category_name}: {e}\")\n",
    "        print(f\"Attempting to proceed with URL as-is...\")\n",
    "\n",
    "    # Capture page source and parse\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    # Extract climber data\n",
    "    climbers = []\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    debug_printed = False\n",
    "    for row in rows:\n",
    "        fname = row.find(\"span\", class_=\"font-normal\")\n",
    "        sname = row.find(\"span\", class_=\"font-bold uppercase\")\n",
    "        if fname and sname:  # Only process rows with names\n",
    "            full_name = f\"{fname.text.strip()} {sname.text.strip()}\"\n",
    "            columns = row.find_all(\"td\")\n",
    "            if len(columns) >= 4:  # Expect picture, name, country, points\n",
    "                # Country: Third column (index 2)\n",
    "                country_td = columns[2]\n",
    "                country_span = country_td.find(\"span\")\n",
    "                country = country_span.text.strip() if country_span else \"N/A\"\n",
    "\n",
    "                # Points: Fourth column (index 3)\n",
    "                points_td = columns[3]\n",
    "                points_spans = points_td.find_all(\"span\")  # Get all spans\n",
    "                points = \"0\"\n",
    "                for span in points_spans:\n",
    "                    text = span.text.strip()\n",
    "                    if text and any(c.isdigit() for c in text):  # Pick span with numbers\n",
    "                        points = text\n",
    "                        break\n",
    "\n",
    "                # Debug if points are 0 for known climbers\n",
    "                if points == \"0\" and full_name in [\"jongwon CHON\", \"anze PEHARC\"] and not debug_printed:\n",
    "                    print(f\"Debug for {full_name}:\")\n",
    "                    print(f\"  Points TD: {points_td.prettify()[:300]}...\")\n",
    "                    print(f\"  Points Spans Found: {[s.text.strip() for s in points_spans]}\")\n",
    "                    debug_printed = True\n",
    "\n",
    "                # Convert points to float to handle decimals, default to 0 if invalid\n",
    "                try:\n",
    "                    points_value = float(points) if points else 0.0\n",
    "                except ValueError:\n",
    "                    points_value = 0.0\n",
    "\n",
    "            else:\n",
    "                country = \"N/A\"\n",
    "                points_value = 0.0\n",
    "                print(f\"Debug: Row for {full_name} has {len(columns)} columns: {row.prettify()[:200]}...\")\n",
    "\n",
    "            climbers.append({\n",
    "                \"name\": full_name,\n",
    "                \"country\": country,\n",
    "                f\"{discipline}_points\": points_value\n",
    "            })\n",
    "\n",
    "    print(f\"Collected {len(climbers)} climbers for {category_name}\")\n",
    "    return climbers\n",
    "\n",
    "#### Modified Merging and Saving Data to CSV\n",
    "def merge_and_save_data(men_boulder, men_lead, men_combined, women_boulder, women_lead, women_combined):\n",
    "    \"\"\"Merge all climber data into one dataset with gender attribute and save to CSV.\"\"\"\n",
    "    os.makedirs(os.path.join(\"../data\", \"ifsc_data\"), exist_ok=True)\n",
    "\n",
    "    def merge_gender_data(boulder_data, lead_data, combined_data, gender):\n",
    "        climbers_dict = {}\n",
    "        for climber in boulder_data:\n",
    "            climbers_dict[climber[\"name\"]] = {\n",
    "                \"name\": climber[\"name\"],\n",
    "                \"country\": climber[\"country\"],\n",
    "                \"gender\": gender,\n",
    "                \"boulder_points\": climber[\"boulder_points\"],\n",
    "                \"lead_points\": 0.0,\n",
    "                \"combined_points\": 0.0\n",
    "            }\n",
    "        for climber in lead_data:\n",
    "            if climber[\"name\"] in climbers_dict:\n",
    "                climbers_dict[climber[\"name\"]][\"lead_points\"] = climber[\"lead_points\"]\n",
    "            else:\n",
    "                climbers_dict[climber[\"name\"]] = {\n",
    "                    \"name\": climber[\"name\"],\n",
    "                    \"country\": climber[\"country\"],\n",
    "                    \"gender\": gender,\n",
    "                    \"boulder_points\": 0.0,\n",
    "                    \"lead_points\": climber[\"lead_points\"],\n",
    "                    \"combined_points\": 0.0\n",
    "                }\n",
    "        for climber in combined_data:\n",
    "            if climber[\"name\"] in climbers_dict:\n",
    "                climbers_dict[climber[\"name\"]][\"combined_points\"] = climber[\"combined_points\"]\n",
    "            else:\n",
    "                climbers_dict[climber[\"name\"]] = {\n",
    "                    \"name\": climber[\"name\"],\n",
    "                    \"country\": climber[\"country\"],\n",
    "                    \"gender\": gender,\n",
    "                    \"boulder_points\": 0.0,\n",
    "                    \"lead_points\": 0.0,\n",
    "                    \"combined_points\": climber[\"combined_points\"]\n",
    "                }\n",
    "        return list(climbers_dict.values())\n",
    "\n",
    "    # Merge data for men and women with gender attribute\n",
    "    men_data = merge_gender_data(men_boulder, men_lead, men_combined, \"male\")\n",
    "    women_data = merge_gender_data(women_boulder, women_lead, women_combined, \"female\")\n",
    "\n",
    "    # Combine men and women data\n",
    "    all_climbers = men_data + women_data\n",
    "\n",
    "    # Define columns including gender\n",
    "    columns = [\"name\", \"country\", \"gender\", \"boulder_points\", \"lead_points\", \"combined_points\"]\n",
    "    climbers_df = pd.DataFrame(all_climbers, columns=columns)\n",
    "\n",
    "    # Save to single CSV file\n",
    "    filepath = os.path.join(\"../data\", \"ifsc_data\", \"ifsc_climbers.csv\")\n",
    "    climbers_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Saved {len(all_climbers)} unique climbers (men and women) to {filepath}\")\n",
    "\n",
    "#### Running the Scraper (unchanged)\n",
    "categories = [\n",
    "    (\"boulder_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\"),\n",
    "    (\"boulder_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\"),\n",
    "    (\"lead_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\"),\n",
    "    (\"lead_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\"),\n",
    "    (\"combined_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=men\"),\n",
    "    (\"combined_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=women\")\n",
    "]\n",
    "\n",
    "print(\"Starting scraping process...\")\n",
    "men_boulder = scrape_ifsc_data(categories[0][1], categories[0][0])\n",
    "women_boulder = scrape_ifsc_data(categories[1][1], categories[1][0])\n",
    "men_lead = scrape_ifsc_data(categories[2][1], categories[2][0])\n",
    "women_lead = scrape_ifsc_data(categories[3][1], categories[3][0])\n",
    "men_combined = scrape_ifsc_data(categories[4][1], categories[4][0])\n",
    "women_combined = scrape_ifsc_data(categories[5][1], categories[5][0])\n",
    "merge_and_save_data(men_boulder, men_lead, men_combined, women_boulder, women_lead, women_combined)\n",
    "print(\"Scraping and merging process completed!\")"
   ],
   "id": "e781e34c35b6ae47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping process...\n",
      "Scraping boulder_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\n",
      "Accepted cookie popup for boulder_men\n",
      "Clicked 'Boulder' tab for boulder_men\n",
      "Boulder rankings data loaded for boulder_men!\n",
      "Collected 214 climbers for boulder_men\n",
      "Scraping boulder_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\n",
      "Accepted cookie popup for boulder_women\n",
      "Clicked 'Boulder' tab for boulder_women\n",
      "Boulder rankings data loaded for boulder_women!\n",
      "Collected 194 climbers for boulder_women\n",
      "Scraping lead_men from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\n",
      "Accepted cookie popup for lead_men\n",
      "Clicked 'Lead' tab for lead_men\n",
      "Lead rankings data loaded for lead_men!\n",
      "Collected 189 climbers for lead_men\n",
      "Scraping lead_women from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\n",
      "Accepted cookie popup for lead_women\n",
      "Clicked 'Lead' tab for lead_women\n",
      "Lead rankings data loaded for lead_women!\n",
      "Collected 175 climbers for lead_women\n",
      "Scraping combined_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=men\n",
      "Accepted cookie popup for combined_men\n",
      "Clicked 'Boulder & Lead' tab for combined_men\n",
      "Boulder & Lead rankings data loaded for combined_men!\n",
      "Collected 108 climbers for combined_men\n",
      "Scraping combined_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=women\n",
      "Accepted cookie popup for combined_women\n",
      "Clicked 'Boulder & Lead' tab for combined_women\n",
      "Boulder & Lead rankings data loaded for combined_women!\n",
      "Collected 108 climbers for combined_women\n",
      "Saved 558 unique climbers (men and women) to ../data/ifsc_data/ifsc_climbers.csv\n",
      "Scraping and merging process completed!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5ccc22685786cd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
