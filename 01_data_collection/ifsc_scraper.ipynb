{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **IFSC Climbing Scraper**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "This notebook scrapes the official **IFSC (International Federation of Sport Climbing) rankings** from [IFSC Rankings](https://www.ifsc-climbing.org/rankings/index) using **Selenium and BeautifulSoup**. It extracts the names, total points, and nationalities of climbers across three disciplines:\n",
    "\n",
    "- **Bouldering** (max 100 points per comp)\n",
    "- **Lead Climbing** (max 100 points per comp)\n",
    "- **Combined (Bouldering & Lead)** (max 200 points per comp)\n",
    "\n",
    "The final dataset consolidates ranking data for both male and female climbers, ensuring each athlete is uniquely recorded with their respective points in different disciplines.\n",
    "\n",
    "For more details on how IFSC scoring works, refer to [this guide](https://www.redbull.com/int-en/climbing-competition-scoring-guide#:~:text=As%20mentioned%20above%20the%20final,score%20each%20athlete%20can%20achieve).\n",
    "\n",
    "---\n",
    "\n",
    "### **Challenges Encountered**\n",
    "\n",
    "During the development of this scraper, several challenges had to be addressed:\n",
    "\n",
    "- **Dynamic Page Elements**: Initially, BeautifulSoup alone was used for scraping, but IFSC rankings pages load data dynamically using JavaScript. This required switching to **Selenium** to interact with the page and wait for content to fully load.\n",
    "\n",
    "- **Cookie Popups**: Some pages display a cookie consent popup that prevents access to rankings. A delay and automated button click were added to bypass this issue.\n",
    "\n",
    "- **Missing Data**: Some climbers do not have recorded points in certain disciplines. These missing values were replaced with **0**.\n",
    "\n",
    "- **Bias in Total Points**: The dataset records **total points across all competitions**, which can be misleading. Climbers who have competed in more events will generally have higher points, even if their individual performances were inconsistent.\n",
    "  - **Potential Improvement**: Scraping the **average rank** of each climber per event would provide a better measure of relative performance. However, this would require navigating additional pages and handling more complex data structures.\n",
    "\n",
    "---\n",
    "Let's get to the scraping"
   ],
   "id": "f021dd3090ba837d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Setup and Imports**\n",
    "Before scraping the data, we need to import the necessary libraries.\n",
    "\n",
    "- **Selenium**: Used for interacting with the dynamic IFSC rankings website.\n",
    "- **BeautifulSoup**: Used for parsing the page source once Selenium loads it.\n",
    "- **Pandas**: Used for structuring and saving the scraped data.\n",
    "- **OS & Time**: Used for file handling and managing delays in page interactions.\n"
   ],
   "id": "c206bd4ab29571b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:42:02.342559Z",
     "start_time": "2025-03-30T20:42:01.833474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ],
   "id": "e781e34c35b6ae47",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Web Scraping Function**\n",
    "To extract ranking data, we define a function that:\n",
    "\n",
    "- **Loads the IFSC rankings page** using Selenium.\n",
    "- **Handles cookie popups** to ensure smooth navigation.\n",
    "- **Clicks the appropriate discipline tab** (Boulder, Lead, or Combined).\n",
    "- **Extracts climber names, countries, and points** using BeautifulSoup.\n",
    "- **Handles missing data** (if a climber has no recorded points in a discipline, we assign `0`).\n",
    "\n",
    "This function will be called separately for each category (Men's and Women's Boulder, Lead, and Combined rankings).\n"
   ],
   "id": "1990cc191838ba52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:42:06.590520Z",
     "start_time": "2025-03-30T20:42:06.578458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scraping IFSC with Points Extraction\n",
    "def scrape_ifsc_data(url, category_name):\n",
    "    \"\"\"Scrape climber names, countries, and points using Selenium with debugging.\"\"\"\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    print(f\"Scraping {category_name} from {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle cookie popup with a slight delay\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", accept_button)\n",
    "        print(f\"Accepted cookie popup for {category_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No cookie popup found or error accepting it for {category_name}: {e}\")\n",
    "\n",
    "    # Determine discipline from category_name\n",
    "    if \"combined\" in category_name:\n",
    "        discipline = \"combined\"\n",
    "        tab_name = \"Boulder & Lead\"\n",
    "    elif \"lead\" in category_name:\n",
    "        discipline = \"lead\"\n",
    "        tab_name = \"Lead\"\n",
    "    else:\n",
    "        discipline = \"boulder\"\n",
    "        tab_name = \"Boulder\"\n",
    "\n",
    "    # Click the appropriate tab\n",
    "    try:\n",
    "        tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//a[contains(@class, 'd3-ty-navigation-large') and contains(text(), '{tab_name}')]\"))\n",
    "        )\n",
    "        tab.click()\n",
    "        print(f\"Clicked '{tab_name}' tab for {category_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"font-normal\"))\n",
    "        )\n",
    "        print(f\"{tab_name} rankings data loaded for {category_name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not click '{tab_name}' tab or load data for {category_name}: {e}\")\n",
    "        print(f\"Attempting to proceed with URL as-is...\")\n",
    "\n",
    "    # Capture page source and parse\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    # Extract climber data\n",
    "    climbers = []\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    debug_printed = False\n",
    "    for row in rows:\n",
    "        fname = row.find(\"span\", class_=\"font-normal\")\n",
    "        sname = row.find(\"span\", class_=\"font-bold uppercase\")\n",
    "        if fname and sname:  # Only process rows with names\n",
    "            full_name = f\"{fname.text.strip()} {sname.text.strip()}\"\n",
    "            columns = row.find_all(\"td\")\n",
    "            if len(columns) >= 4:  # Expect picture, name, country, points\n",
    "                # Country: Third column (index 2)\n",
    "                country_td = columns[2]\n",
    "                country_span = country_td.find(\"span\")\n",
    "                country = country_span.text.strip() if country_span else \"N/A\"\n",
    "\n",
    "                # Points: Fourth column (index 3)\n",
    "                points_td = columns[3]\n",
    "                points_spans = points_td.find_all(\"span\")  # Get all spans\n",
    "                points = \"0\"\n",
    "                for span in points_spans:\n",
    "                    text = span.text.strip()\n",
    "                    if text and any(c.isdigit() for c in text):  # Pick span with numbers\n",
    "                        points = text\n",
    "                        break\n",
    "\n",
    "                # Debug if points are 0 for known climbers\n",
    "                if points == \"0\" and full_name in [\"jongwon CHON\", \"anze PEHARC\"] and not debug_printed:\n",
    "                    print(f\"Debug for {full_name}:\")\n",
    "                    print(f\"  Points TD: {points_td.prettify()[:300]}...\")\n",
    "                    print(f\"  Points Spans Found: {[s.text.strip() for s in points_spans]}\")\n",
    "                    debug_printed = True\n",
    "\n",
    "                # Convert points to float to handle decimals, default to 0 if invalid\n",
    "                try:\n",
    "                    points_value = float(points) if points else 0.0\n",
    "                except ValueError:\n",
    "                    points_value = 0.0\n",
    "\n",
    "            else:\n",
    "                country = \"N/A\"\n",
    "                points_value = 0.0\n",
    "                print(f\"Debug: Row for {full_name} has {len(columns)} columns: {row.prettify()[:200]}...\")\n",
    "\n",
    "            climbers.append({\n",
    "                \"name\": full_name,\n",
    "                \"country\": country,\n",
    "                f\"{discipline}_points\": points_value\n",
    "            })\n",
    "\n",
    "    print(f\"Collected {len(climbers)} climbers for {category_name}\")\n",
    "    return climbers"
   ],
   "id": "f5ccc22685786cd3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Merging and Saving the Data**\n",
    "Once we have scraped rankings for each category, we need to merge them into a single dataset.\n",
    "\n",
    "- **Combining disciplines**: Climbers may have rankings in Boulder, Lead, and Combined events. We ensure each climber appears once, with separate columns for each discipline’s points.\n",
    "- **Adding gender information**: We label each climber as \"male\" or \"female\" based on their category.\n",
    "- **Saving to CSV**: The final dataset is stored as a CSV file for further analysis.\n"
   ],
   "id": "37977fad19ad76fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:42:11.368361Z",
     "start_time": "2025-03-30T20:42:11.362505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merging and Saving Data to CSV\n",
    "def merge_and_save_data(men_boulder, men_lead, men_combined, women_boulder, women_lead, women_combined):\n",
    "    \"\"\"Merge all climber data into one dataset with gender attribute and save to CSV.\"\"\"\n",
    "    os.makedirs(os.path.join(\"../data\", \"ifsc_data\"), exist_ok=True)\n",
    "\n",
    "    def merge_gender_data(boulder_data, lead_data, combined_data, gender):\n",
    "        climbers_dict = {}\n",
    "        for climber in boulder_data:\n",
    "            climbers_dict[climber[\"name\"]] = {\n",
    "                \"name\": climber[\"name\"],\n",
    "                \"country\": climber[\"country\"],\n",
    "                \"gender\": gender,\n",
    "                \"boulder_points\": climber[\"boulder_points\"],\n",
    "                \"lead_points\": 0.0,\n",
    "                \"combined_points\": 0.0\n",
    "            }\n",
    "        for climber in lead_data:\n",
    "            if climber[\"name\"] in climbers_dict:\n",
    "                climbers_dict[climber[\"name\"]][\"lead_points\"] = climber[\"lead_points\"]\n",
    "            else:\n",
    "                climbers_dict[climber[\"name\"]] = {\n",
    "                    \"name\": climber[\"name\"],\n",
    "                    \"country\": climber[\"country\"],\n",
    "                    \"gender\": gender,\n",
    "                    \"boulder_points\": 0.0,\n",
    "                    \"lead_points\": climber[\"lead_points\"],\n",
    "                    \"combined_points\": 0.0\n",
    "                }\n",
    "        for climber in combined_data:\n",
    "            if climber[\"name\"] in climbers_dict:\n",
    "                climbers_dict[climber[\"name\"]][\"combined_points\"] = climber[\"combined_points\"]\n",
    "            else:\n",
    "                climbers_dict[climber[\"name\"]] = {\n",
    "                    \"name\": climber[\"name\"],\n",
    "                    \"country\": climber[\"country\"],\n",
    "                    \"gender\": gender,\n",
    "                    \"boulder_points\": 0.0,\n",
    "                    \"lead_points\": 0.0,\n",
    "                    \"combined_points\": climber[\"combined_points\"]\n",
    "                }\n",
    "        return list(climbers_dict.values())\n",
    "\n",
    "    # Merge data for men and women with gender attribute\n",
    "    men_data = merge_gender_data(men_boulder, men_lead, men_combined, \"male\")\n",
    "    women_data = merge_gender_data(women_boulder, women_lead, women_combined, \"female\")\n",
    "\n",
    "    # Combine men and women data\n",
    "    all_climbers = men_data + women_data\n",
    "\n",
    "    # Define columns including gender\n",
    "    columns = [\"name\", \"country\", \"gender\", \"boulder_points\", \"lead_points\", \"combined_points\"]\n",
    "    climbers_df = pd.DataFrame(all_climbers, columns=columns)\n",
    "\n",
    "    # Save to single CSV file\n",
    "    filepath = os.path.join(\"../data\", \"ifsc_data\", \"ifsc_climbers.csv\")\n",
    "    climbers_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Saved {len(all_climbers)} unique climbers (men and women) to {filepath}\")"
   ],
   "id": "9909a13426878a7f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we have defined our scraping and data processing functions, we can:\n",
    "\n",
    "- **Run the scraper** for each category (Men’s and Women’s Boulder, Lead, and Combined).\n",
    "- **Merge the results** into a single dataset.\n",
    "- **Save the dataset** as a CSV file for further analysis."
   ],
   "id": "e51d6ebc82ac1817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:46:24.935100Z",
     "start_time": "2025-03-30T20:45:52.564987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Running the Scraper\n",
    "categories = [\n",
    "    (\"boulder_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\"),\n",
    "    (\"boulder_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\"),\n",
    "    (\"lead_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\"),\n",
    "    (\"lead_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\"),\n",
    "    (\"combined_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=men\"),\n",
    "    (\"combined_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=women\")\n",
    "]\n",
    "\n",
    "print(\"Starting scraping process...\")\n",
    "men_boulder = scrape_ifsc_data(categories[0][1], categories[0][0])\n",
    "women_boulder = scrape_ifsc_data(categories[1][1], categories[1][0])\n",
    "men_lead = scrape_ifsc_data(categories[2][1], categories[2][0])\n",
    "women_lead = scrape_ifsc_data(categories[3][1], categories[3][0])\n",
    "men_combined = scrape_ifsc_data(categories[4][1], categories[4][0])\n",
    "women_combined = scrape_ifsc_data(categories[5][1], categories[5][0])\n",
    "merge_and_save_data(men_boulder, men_lead, men_combined, women_boulder, women_lead, women_combined)\n",
    "print(\"Scraping and merging process completed!\")"
   ],
   "id": "fb8f53d5b9edb37c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping process...\n",
      "Scraping boulder_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\n",
      "Accepted cookie popup for boulder_men\n",
      "Clicked 'Boulder' tab for boulder_men\n",
      "Boulder rankings data loaded for boulder_men!\n",
      "Collected 202 climbers for boulder_men\n",
      "Scraping boulder_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\n",
      "Accepted cookie popup for boulder_women\n",
      "Clicked 'Boulder' tab for boulder_women\n",
      "Boulder rankings data loaded for boulder_women!\n",
      "Collected 179 climbers for boulder_women\n",
      "Scraping lead_men from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\n",
      "Accepted cookie popup for lead_men\n",
      "Clicked 'Lead' tab for lead_men\n",
      "Lead rankings data loaded for lead_men!\n",
      "Collected 170 climbers for lead_men\n",
      "Scraping lead_women from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\n",
      "Accepted cookie popup for lead_women\n",
      "Clicked 'Lead' tab for lead_women\n",
      "Lead rankings data loaded for lead_women!\n",
      "Collected 163 climbers for lead_women\n",
      "Scraping combined_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=men\n",
      "Accepted cookie popup for combined_men\n",
      "Clicked 'Boulder & Lead' tab for combined_men\n",
      "Boulder & Lead rankings data loaded for combined_men!\n",
      "Collected 99 climbers for combined_men\n",
      "Scraping combined_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder-lead&category=women\n",
      "Accepted cookie popup for combined_women\n",
      "Clicked 'Boulder & Lead' tab for combined_women\n",
      "Boulder & Lead rankings data loaded for combined_women!\n",
      "Collected 100 climbers for combined_women\n",
      "Saved 517 unique climbers (men and women) to ../data/ifsc_data/ifsc_climbers.csv\n",
      "Scraping and merging process completed!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The final dataset contains information about competitive climbers from the IFSC rankings. Each row represents a unique climber with the following attributes:\n",
    "\n",
    "- **name**: The full name of the climber.\n",
    "- **country**: The climber's country of representation.\n",
    "- **gender**: Male or female.\n",
    "- **boulder_points**: Total points earned in bouldering\n",
    "- **lead_points**: Total points earned in lead climbing\n",
    "- **combined_points**: Total points earned in the combined event\n",
    "\n",
    "As a last step, we can preview the first few rows of our IFSC dataset"
   ],
   "id": "94d4933d7a603b00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:52:03.119139Z",
     "start_time": "2025-03-30T20:52:03.109353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the saved dataset to preview the results\n",
    "df = pd.read_csv(\"../data/ifsc_data/ifsc_climbers.csv\")\n",
    "df.head()"
   ],
   "id": "99a1368c970e658a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              name country gender  boulder_points  lead_points  \\\n",
       "0    sorato ANRAKU     JPN   male          3640.0       2971.0   \n",
       "1       dohyun LEE     KOR   male          3183.0       2343.0   \n",
       "2  meichi NARASAKI     JPN   male          2860.0          0.0   \n",
       "3   tomoa NARASAKI     JPN   male          2849.0        765.0   \n",
       "4    sohta AMAGASA     JPN   male          2619.0          0.0   \n",
       "\n",
       "   combined_points  \n",
       "0           6313.0  \n",
       "1           4320.0  \n",
       "2              0.0  \n",
       "3           3600.0  \n",
       "4              0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>boulder_points</th>\n",
       "      <th>lead_points</th>\n",
       "      <th>combined_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sorato ANRAKU</td>\n",
       "      <td>JPN</td>\n",
       "      <td>male</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>6313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dohyun LEE</td>\n",
       "      <td>KOR</td>\n",
       "      <td>male</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>2343.0</td>\n",
       "      <td>4320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meichi NARASAKI</td>\n",
       "      <td>JPN</td>\n",
       "      <td>male</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomoa NARASAKI</td>\n",
       "      <td>JPN</td>\n",
       "      <td>male</td>\n",
       "      <td>2849.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sohta AMAGASA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>male</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21b4917a9a08141d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
