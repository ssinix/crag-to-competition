{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Find ifsc climbers profiles on 8a.nu using automated search",
   "id": "52291a3716d36845"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Function to capitalize first letters only\n",
    "def capitalize_name(name):\n",
    "    return \" \".join(word.capitalize() for word in name.split())\n",
    "\n",
    "# Function to append a row to CSV\n",
    "def append_to_csv(data, output_file):\n",
    "    \"\"\"Append a single row to the CSV file.\"\"\"\n",
    "    df = pd.DataFrame([data])\n",
    "    if os.path.exists(output_file):\n",
    "        df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Optional nickname lookup table\n",
    "NICKNAME_LOOKUP = {\n",
    "    \"Nikolay Rusev\": [\"Niki Rusev\"],\n",
    "    \"Alexander Megos\": [\"Alex Megos\"],\n",
    "    # Add more known aliases here as needed\n",
    "}\n",
    "\n",
    "# Function to search for a climber on 8a.nu and collect the highest probable profile link\n",
    "def search_8a_nu(climber_name, country, driver, output_file, similarity_threshold=90):\n",
    "    \"\"\"Search 8a.nu for a climber and save the highest probable profile link with ascents to CSV.\"\"\"\n",
    "    # Capitalize only first letters\n",
    "    climber_name = capitalize_name(climber_name)\n",
    "    encoded_name = urllib.parse.quote(climber_name)\n",
    "    search_url = f\"https://www.8a.nu/search/users?query={encoded_name}\"\n",
    "    print(f\"Searching for {climber_name} from {country} on 8a.nu...\")\n",
    "\n",
    "    try:\n",
    "        # Navigate directly to the search URL\n",
    "        driver.get(search_url)\n",
    "\n",
    "        # Wait for search results table rows to load\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"tr\"))\n",
    "        )\n",
    "\n",
    "        # Parse the search results page\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Find climber profile links with ascent counts\n",
    "        candidates = []\n",
    "        result_rows = soup.find_all(\"tr\")\n",
    "        nicknames = NICKNAME_LOOKUP.get(climber_name, [])  # Get possible nicknames\n",
    "        for row in result_rows:\n",
    "            name_link = row.find(\"a\", href=lambda href: href and \"/user/\" in href)\n",
    "            if name_link:\n",
    "                link_text = name_link.text.strip()\n",
    "                link_href = name_link[\"href\"]\n",
    "                # Calculate similarity with IFSC name or check nicknames\n",
    "                similarity = fuzz.partial_ratio(climber_name.lower(), link_text.lower())\n",
    "                is_nickname = any(nick.lower() in link_text.lower() for nick in nicknames)\n",
    "                if similarity >= similarity_threshold or is_nickname:\n",
    "                    # Extract country from the row\n",
    "                    country_td = row.find(\"td\", class_=\"col-flag\")\n",
    "                    found_country = \"N/A\"\n",
    "                    country_code = \"N/A\"\n",
    "                    if country_td:\n",
    "                        country_text = country_td.text.strip()\n",
    "                        found_country = country_text if country_text else \"N/A\"\n",
    "                        country_span = country_td.find(\"span\", class_=lambda x: x and x.startswith(\"f-\"))\n",
    "                        if country_span and country_span.get(\"class\"):\n",
    "                            try:\n",
    "                                country_code = country_span[\"class\"][0].split(\"-\")[1].upper()\n",
    "                            except (IndexError, AttributeError):\n",
    "                                country_code = \"N/A\"\n",
    "\n",
    "                    # Extract ascent count\n",
    "                    ascent_td = row.find(\"td\", class_=\"col-ascents\")\n",
    "                    ascent_count = 0\n",
    "                    if ascent_td:\n",
    "                        ascent_text = ascent_td.text.strip().replace(\" \", \"\")\n",
    "                        try:\n",
    "                            ascent_count = int(ascent_text) if ascent_text else 0\n",
    "                        except ValueError:\n",
    "                            ascent_count = 0\n",
    "\n",
    "                    # Only include profiles with ascents > 0\n",
    "                    full_url = f\"https://www.8a.nu{link_href}\"\n",
    "                    if ascent_count > 0:\n",
    "                        candidates.append({\n",
    "                            \"url\": full_url,\n",
    "                            \"name\": link_text,\n",
    "                            \"similarity\": similarity if not is_nickname else 100,  # Nicknames get max score\n",
    "                            \"country\": found_country,\n",
    "                            \"country_code\": country_code,\n",
    "                            \"ascents\": ascent_count,\n",
    "                            \"verified\": country == found_country or country == country_code\n",
    "                        })\n",
    "                        print(f\"Found candidate profile for {climber_name}: {full_url} (Name: {link_text}, Similarity: {similarity}%, Country: {found_country}, Ascents: {ascent_count})\")\n",
    "\n",
    "        # Select the highest probable profile\n",
    "        profile_link = None\n",
    "        if candidates:\n",
    "            best_candidate = max(candidates, key=lambda x: x[\"similarity\"])  # Highest similarity\n",
    "            profile_link = best_candidate[\"url\"]\n",
    "            if best_candidate[\"verified\"]:\n",
    "                print(f\"Selected verified profile: {profile_link} (Similarity: {best_candidate['similarity']}%)\")\n",
    "            else:\n",
    "                print(f\"Selected potential profile: {profile_link} (Similarity: {best_candidate['similarity']}%, expected country: {country})\")\n",
    "\n",
    "        # Only save to CSV if a profile with ascents is found\n",
    "        if profile_link:\n",
    "            data = {\"name\": climber_name, \"possible_profile_link_1\": profile_link}\n",
    "            print(f\"Selected 1 profile with ascents for {climber_name}\")\n",
    "            append_to_csv(data, output_file)\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"No profile with ascents found for {climber_name}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for {climber_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main script to process IFSC climbers and save to CSV incrementally\n",
    "def process_ifsc_climbers(ifsc_dir=\"../data/ifsc_data\", output_dir=\"../data/8anu_data\"):\n",
    "    \"\"\"Process IFSC climbers and save their highest probable 8a.nu profile link with ascents to CSV.\"\"\"\n",
    "    men_df = pd.read_csv(f\"{ifsc_dir}/men_climbers.csv\")\n",
    "    women_df = pd.read_csv(f\"{ifsc_dir}/women_climbers.csv\")\n",
    "    climbers_df = pd.concat([men_df, women_df], ignore_index=True)\n",
    "\n",
    "    output_file = f\"{output_dir}/8a_nu_profiles.csv\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize a single WebDriver instance\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    total_climbers = len(climbers_df)\n",
    "    processed_with_profiles = 0\n",
    "    try:\n",
    "        for index, row in climbers_df.iterrows():\n",
    "            climber_name = row[\"name\"]\n",
    "            country = row[\"country\"]\n",
    "            result = search_8a_nu(climber_name, country, driver, output_file)\n",
    "            if result:\n",
    "                processed_with_profiles += 1\n",
    "            print(f\"Processed {index + 1}/{total_climbers} climbers ({processed_with_profiles} with profiles and ascents)\")\n",
    "    finally:\n",
    "        driver.quit()  # Ensure driver closes even if an error occurs\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting 8a.nu scraping process...\")\n",
    "    process_ifsc_climbers()\n",
    "    print(\"8a.nu scraping process completed!\")"
   ],
   "id": "35fd9bb29a09e8c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
