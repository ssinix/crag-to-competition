{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This notebook scrapes climber names, country of the climber and total points by category from the International Federation of Sport Climbing (IFSC) rankings website. It extracts data for both boulder and lead categories, for men and women.\n"
   ],
   "id": "f021dd3090ba837d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T11:15:47.603561Z",
     "start_time": "2025-03-10T11:15:32.522861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "### Scraping IFSC with Robust Points Extraction\n",
    "\n",
    "def scrape_ifsc_data(url, category_name):\n",
    "    \"\"\"Scrape climber names, countries, and points using Selenium with debugging.\"\"\"\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    print(f\"Scraping {category_name} from {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle cookie popup with a slight delay\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", accept_button)\n",
    "        print(f\"Accepted cookie popup for {category_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No cookie popup found or error accepting it for {category_name}: {e}\")\n",
    "\n",
    "    # Determine discipline from category_name\n",
    "    discipline = \"lead\" if \"lead\" in category_name else \"boulder\"\n",
    "    tab_name = \"Lead\" if discipline == \"lead\" else \"Boulder\"\n",
    "\n",
    "    # Click the appropriate tab\n",
    "    try:\n",
    "        tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//a[contains(@class, 'd3-ty-navigation-large') and contains(text(), '{tab_name}')]\"))\n",
    "        )\n",
    "        tab.click()\n",
    "        print(f\"Clicked '{tab_name}' tab for {category_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"font-normal\"))\n",
    "        )\n",
    "        print(f\"{tab_name} rankings data loaded for {category_name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not click '{tab_name}' tab or load data for {category_name}: {e}\")\n",
    "        print(f\"Attempting to proceed with URL as-is...\")\n",
    "\n",
    "    # Capture page source and parse\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    # Extract climber data\n",
    "    climbers = []\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    debug_printed = False\n",
    "    for row in rows:\n",
    "        fname = row.find(\"span\", class_=\"font-normal\")\n",
    "        sname = row.find(\"span\", class_=\"font-bold uppercase\")\n",
    "        if fname and sname:  # Only process rows with names\n",
    "            full_name = f\"{fname.text.strip()} {sname.text.strip()}\"\n",
    "            columns = row.find_all(\"td\")\n",
    "            if len(columns) >= 4:  # Expect picture, name, country, points\n",
    "                # Country: Third column (index 2)\n",
    "                country_td = columns[2]\n",
    "                country_span = country_td.find(\"span\")\n",
    "                country = country_span.text.strip() if country_span else \"N/A\"\n",
    "\n",
    "                # Points: Fourth column (index 3)\n",
    "                points_td = columns[3]\n",
    "                points_spans = points_td.find_all(\"span\")  # Get all spans\n",
    "                points = \"0\"\n",
    "                for span in points_spans:\n",
    "                    text = span.text.strip()\n",
    "                    if text and any(c.isdigit() for c in text):  # Pick span with numbers\n",
    "                        points = text\n",
    "                        break\n",
    "\n",
    "                # Debug if points are 0 for known climbers\n",
    "                if points == \"0\" and full_name in [\"jongwon CHON\", \"anze PEHARC\"] and not debug_printed:\n",
    "                    print(f\"Debug for {full_name}:\")\n",
    "                    print(f\"  Points TD: {points_td.prettify()[:300]}...\")\n",
    "                    print(f\"  Points Spans Found: {[s.text.strip() for s in points_spans]}\")\n",
    "                    debug_printed = True\n",
    "\n",
    "                # Convert points to float to handle decimals, default to 0 if invalid\n",
    "                try:\n",
    "                    points_value = float(points) if points else 0.0\n",
    "                except ValueError:\n",
    "                    points_value = 0.0\n",
    "\n",
    "            else:\n",
    "                country = \"N/A\"\n",
    "                points_value = 0.0\n",
    "                print(f\"Debug: Row for {full_name} has {len(columns)} columns: {row.prettify()[:200]}...\")\n",
    "\n",
    "            climbers.append({\n",
    "                \"name\": full_name,\n",
    "                \"country\": country,\n",
    "                f\"{discipline}_points\": points_value\n",
    "            })\n",
    "\n",
    "    print(f\"Collected {len(climbers)} climbers for {category_name}\")\n",
    "    return climbers\n",
    "\n",
    "\n",
    "#### Merging and Saving Data to CSV\n",
    "\n",
    "def merge_and_save_data(men_boulder, men_lead, women_boulder, women_lead):\n",
    "    \"\"\"Merge data by gender, remove duplicates, and save to CSV.\"\"\"\n",
    "    os.makedirs(os.path.join(\"data\", \"ifsc_data\"), exist_ok=True)\n",
    "\n",
    "    def merge_data(boulder_data, lead_data):\n",
    "        climbers_dict = {}\n",
    "        for climber in boulder_data:\n",
    "            climbers_dict[climber[\"name\"]] = {\n",
    "                \"name\": climber[\"name\"],\n",
    "                \"country\": climber[\"country\"],\n",
    "                \"boulder_points\": climber[\"boulder_points\"],\n",
    "                \"lead_points\": 0.0\n",
    "            }\n",
    "        for climber in lead_data:\n",
    "            if climber[\"name\"] in climbers_dict:\n",
    "                climbers_dict[climber[\"name\"]][\"lead_points\"] = climber[\"lead_points\"]\n",
    "            else:\n",
    "                climbers_dict[climber[\"name\"]] = {\n",
    "                    \"name\": climber[\"name\"],\n",
    "                    \"country\": climber[\"country\"],\n",
    "                    \"boulder_points\": 0.0,\n",
    "                    \"lead_points\": climber[\"lead_points\"]\n",
    "                }\n",
    "        return list(climbers_dict.values())\n",
    "\n",
    "    men_data = merge_data(men_boulder, men_lead)\n",
    "    women_data = merge_data(women_boulder, women_lead)\n",
    "\n",
    "    columns = [\"name\", \"country\", \"boulder_points\", \"lead_points\"]\n",
    "    men_df = pd.DataFrame(men_data, columns=columns)\n",
    "    women_df = pd.DataFrame(women_data, columns=columns)\n",
    "\n",
    "    men_filepath = os.path.join(\"data\", \"ifsc_data\", \"men_climbers.csv\")\n",
    "    women_filepath = os.path.join(\"data\", \"ifsc_data\", \"women_climbers.csv\")\n",
    "\n",
    "    men_df.to_csv(men_filepath, index=False)\n",
    "    women_df.to_csv(women_filepath, index=False)\n",
    "\n",
    "    print(f\"Saved {len(men_data)} unique male climbers to {men_filepath}\")\n",
    "    print(f\"Saved {len(women_data)} unique female climbers to {women_filepath}\")\n",
    "\n",
    "\n",
    "#### Running the Scraper\n",
    "\n",
    "categories = [\n",
    "    (\"boulder_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\"),\n",
    "    (\"boulder_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\"),\n",
    "    (\"lead_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\"),\n",
    "    (\"lead_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\")\n",
    "]\n",
    "\n",
    "print(\"Starting scraping process...\")\n",
    "men_boulder = scrape_ifsc_data(categories[0][1], categories[0][0])\n",
    "women_boulder = scrape_ifsc_data(categories[1][1], categories[1][0])\n",
    "men_lead = scrape_ifsc_data(categories[2][1], categories[2][0])\n",
    "women_lead = scrape_ifsc_data(categories[3][1], categories[3][0])\n",
    "merge_and_save_data(men_boulder, men_lead, women_boulder, women_lead)\n",
    "print(\"Scraping and merging process completed!\")"
   ],
   "id": "e6e8b8ff5461b661",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping process...\n",
      "Scraping boulder_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\n",
      "Accepted cookie popup for boulder_men\n",
      "Clicked 'Boulder' tab for boulder_men\n",
      "Boulder rankings data loaded for boulder_men!\n",
      "Collected 214 climbers for boulder_men\n",
      "Scraping boulder_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\n",
      "Accepted cookie popup for boulder_women\n",
      "Clicked 'Boulder' tab for boulder_women\n",
      "Boulder rankings data loaded for boulder_women!\n",
      "Collected 194 climbers for boulder_women\n",
      "Scraping lead_men from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\n",
      "Accepted cookie popup for lead_men\n",
      "Clicked 'Lead' tab for lead_men\n",
      "Lead rankings data loaded for lead_men!\n",
      "Collected 189 climbers for lead_men\n",
      "Scraping lead_women from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\n",
      "Accepted cookie popup for lead_women\n",
      "Clicked 'Lead' tab for lead_women\n",
      "Lead rankings data loaded for lead_women!\n",
      "Collected 175 climbers for lead_women\n",
      "Saved 297 unique male climbers to ifsc_data/men_climbers.csv\n",
      "Saved 261 unique female climbers to ifsc_data/women_climbers.csv\n",
      "Scraping and merging process completed!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3332bedb4a80b436"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
