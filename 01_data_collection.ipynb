{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This notebook scrapes climber names from the International Federation of Sport Climbing (IFSC) rankings website. It extracts data for both boulder and lead categories, for men and women.\n",
    "\n",
    "### Setup and Imports\n",
    "Let's start by importing the necessary libraries and suppressing warnings."
   ],
   "id": "f021dd3090ba837d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:41:54.566466Z",
     "start_time": "2025-03-08T18:41:54.560189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ],
   "id": "6b8d799e16c98615",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### Scraping IFSC",
   "id": "702232a166006465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:41:56.506688Z",
     "start_time": "2025-03-08T18:41:56.495812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_ifsc_names(url, category_name):\n",
    "    \"\"\"Scrape climber names using Selenium for dynamic content.\"\"\"\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    print(f\"Scraping {category_name} from {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle cookie popup\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        print(f\"Accepted cookie popup for {category_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No cookie popup found or error accepting it for {category_name}: {e}\")\n",
    "\n",
    "    # Determine discipline from category_name\n",
    "    discipline = \"lead\" if \"lead\" in category_name else \"boulder\"\n",
    "    tab_name = \"Lead\" if discipline == \"lead\" else \"Boulder\"\n",
    "\n",
    "    # Click the appropriate tab\n",
    "    try:\n",
    "        tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//a[contains(@class, 'd3-ty-navigation-large') and contains(text(), '{tab_name}')]\"))\n",
    "        )\n",
    "        tab.click()\n",
    "        print(f\"Clicked '{tab_name}' tab for {category_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"font-normal\"))\n",
    "        )\n",
    "        print(f\"{tab_name} rankings data loaded for {category_name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not click '{tab_name}' tab or load data for {category_name}: {e}\")\n",
    "        print(f\"Attempting to proceed with URL as-is...\")\n",
    "\n",
    "    # Capture page source and parse\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    # Extract names\n",
    "    first_names = soup.find_all(\"span\", class_=\"font-normal\")\n",
    "    surnames = soup.find_all(\"span\", class_=\"font-bold uppercase\")\n",
    "\n",
    "    print(f\"Found {len(first_names)} first names for {category_name}\")\n",
    "    print(f\"Found {len(surnames)} surnames for {category_name}\")\n",
    "\n",
    "    climbers = []\n",
    "    if len(first_names) == len(surnames) and len(first_names) > 0:\n",
    "        for fname, sname in zip(first_names, surnames):\n",
    "            full_name = f\"{fname.text.strip()} {sname.text.strip()}\"\n",
    "            climbers.append({\"name\": full_name})\n",
    "    else:\n",
    "        print(f\"Mismatch in {category_name}â€”trying athlete links\")\n",
    "        athlete_links = soup.find_all(\"a\", class_=\"hover:text-blue-aa\")\n",
    "        for link in athlete_links:\n",
    "            name_span = link.find(\"span\")\n",
    "            if name_span:\n",
    "                fname = name_span.find(\"span\", class_=\"font-normal\")\n",
    "                sname = name_span.find(\"span\", class_=\"font-bold uppercase\")\n",
    "                if fname and sname:\n",
    "                    full_name = f\"{fname.text.strip()} {sname.text.strip()}\"\n",
    "                    climbers.append({\"name\": full_name})\n",
    "\n",
    "    print(f\"Collected {len(climbers)} climbers for {category_name}\")\n",
    "    return climbers"
   ],
   "id": "44680fed85798f1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:41:57.302820Z",
     "start_time": "2025-03-08T18:41:57.298696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_to_csv(data, filename, columns):\n",
    "    \"\"\"Save data to CSV in ifsc_data folder.\"\"\"\n",
    "    # Create ifsc_data folder if it doesn't exist\n",
    "    os.makedirs(\"ifsc_data\", exist_ok=True)\n",
    "    filepath = os.path.join(\"ifsc_data\", filename)\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved {len(data)} rows to {filepath}\")"
   ],
   "id": "4f538e545e117959",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:41:59.188181Z",
     "start_time": "2025-03-08T18:41:59.183905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    print(\"Starting scraping process...\")\n",
    "\n",
    "    # Define categories and URLs\n",
    "    categories = [\n",
    "        (\"boulder_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\"),\n",
    "        (\"boulder_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\"),\n",
    "        (\"lead_men\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\"),\n",
    "        (\"lead_women\", \"https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\")\n",
    "    ]\n",
    "\n",
    "    # Scrape and save each category\n",
    "    for category_name, url in categories:\n",
    "        climbers = scrape_ifsc_names(url, category_name)\n",
    "        save_to_csv(climbers, f\"{category_name}.csv\", [\"name\"])\n",
    "        print(f\"Finished {category_name}\\n\")"
   ],
   "id": "16b09307a17592f2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:42:16.256242Z",
     "start_time": "2025-03-08T18:42:01.563346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "26e4f36de9f34ba5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping process...\n",
      "Scraping boulder_men from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=men\n",
      "Accepted cookie popup for boulder_men\n",
      "Clicked 'Boulder' tab for boulder_men\n",
      "Boulder rankings data loaded for boulder_men!\n",
      "Found 210 first names for boulder_men\n",
      "Found 210 surnames for boulder_men\n",
      "Collected 210 climbers for boulder_men\n",
      "Saved 210 rows to ifsc_data/boulder_men.csv\n",
      "Finished boulder_men\n",
      "\n",
      "Scraping boulder_women from https://www.ifsc-climbing.org/rankings/index?discipline=boulder&category=women\n",
      "Accepted cookie popup for boulder_women\n",
      "Clicked 'Boulder' tab for boulder_women\n",
      "Boulder rankings data loaded for boulder_women!\n",
      "Found 186 first names for boulder_women\n",
      "Found 186 surnames for boulder_women\n",
      "Collected 186 climbers for boulder_women\n",
      "Saved 186 rows to ifsc_data/boulder_women.csv\n",
      "Finished boulder_women\n",
      "\n",
      "Scraping lead_men from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=men\n",
      "Accepted cookie popup for lead_men\n",
      "Clicked 'Lead' tab for lead_men\n",
      "Lead rankings data loaded for lead_men!\n",
      "Found 189 first names for lead_men\n",
      "Found 189 surnames for lead_men\n",
      "Collected 189 climbers for lead_men\n",
      "Saved 189 rows to ifsc_data/lead_men.csv\n",
      "Finished lead_men\n",
      "\n",
      "Scraping lead_women from https://www.ifsc-climbing.org/rankings/index?discipline=lead&category=women\n",
      "Accepted cookie popup for lead_women\n",
      "Clicked 'Lead' tab for lead_women\n",
      "Lead rankings data loaded for lead_women!\n",
      "Found 175 first names for lead_women\n",
      "Found 175 surnames for lead_women\n",
      "Collected 175 climbers for lead_women\n",
      "Saved 175 rows to ifsc_data/lead_women.csv\n",
      "Finished lead_women\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "983f7d67126ecc09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
